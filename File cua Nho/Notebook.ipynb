{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b9c3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpmath import mp\n",
    "importlib.reload(utils)\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "964a62cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad6d9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(\"Thư mục hiện tại:\", os.getcwd())\n",
    "# print(\"File utils nằm ở:\", utils.__file__)\n",
    "# # CoRT_builder là module chứa class CoRT, ta cần import module để check file\n",
    "# import CoRT_builder\n",
    "# print(\"File CoRT_builder nằm ở:\", CoRT_builder.__file__)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33e90d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OVER CONDITIONING\n",
    "# n_target = 100\n",
    "# n_source = 200\n",
    "# p = 200\n",
    "# K = 5\n",
    "# Ka = 3\n",
    "# h = 30\n",
    "# lamda = 0.05\n",
    "# # s_vector = [0.4, 0.4, 0.4, 0.5, 0.5, 0.5, -0.6, -0.6, -0.6, -0.6]\n",
    "# s_vector = [0,0,0,0,0,0,0,0,0,0]\n",
    "# T = 5\n",
    "# s = len(s_vector)\n",
    "# iteration = 10\n",
    "# CoRT_model = CoRT(alpha=lamda)\n",
    "# p_value_list = []\n",
    "\n",
    "# # target_data, source_data = CoRT.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "# # similar_source_index = CoRT.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "# # print(target_data)\n",
    "# # print(similar_source_index)\n",
    "\n",
    "# total_false_positives_detected = 0\n",
    "# total_false_positives_rejected = 0\n",
    "\n",
    "# for iter in range(iteration):\n",
    "#     print(f\"Processing iteration {iter+1}\")\n",
    "\n",
    "#     target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "#     similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "\n",
    "#     X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "#     model = Lasso(alpha=lamda, fit_intercept=False, random_state=42)\n",
    "#     model.fit(X_combined, y_combined.ravel())\n",
    "#     beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "#     active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "\n",
    "#     if len(active_indices) == 0:\n",
    "#       print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "#       continue\n",
    "\n",
    "#     j = np.random.choice(len(active_indices))\n",
    "\n",
    "#     X_target = target_data[\"X\"]\n",
    "#     y_target = target_data[\"y\"]\n",
    "#     X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "#     etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "#     Sigma = np.eye(n_target)\n",
    "#     b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "#     a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "#     folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "#     L_train, R_train = utils.get_Z_train(etajTy, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "#     L_val, R_val = utils.get_Z_val(folds, T, K, a_global, b_global, etajTy, lamda, source_data)\n",
    "#     L_CoRT, R_CoRT = utils.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, etajTy)\n",
    "\n",
    "#     L_final, R_final = utils.combine_Z(L_train, R_train, L_val, R_val, L_CoRT, R_CoRT)\n",
    "\n",
    "#     etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "#     sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "#     truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "#     p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)\n",
    "#     if p_value is not None:\n",
    "#       total_false_positives_detected += 1\n",
    "#       if p_value <= lamda:\n",
    "#           total_false_positives_rejected += 1\n",
    "#     p_value_list.append(p_value.item())\n",
    "\n",
    "# FPR = 0\n",
    "# if total_false_positives_detected > 0:\n",
    "#     FPR = total_false_positives_rejected / total_false_positives_detected\n",
    "\n",
    "# print(FPR, \"gay\")\n",
    "# plt.hist(p_value_list, bins=10, density=True, edgecolor='black')\n",
    "# plt.title(\"Histogram of p_values\")\n",
    "# plt.xlabel(\"p_value\")\n",
    "# plt.ylabel(\"Density\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b5e77",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2783006947.py, line 65)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif R_CoRT <= z_k\u001b[39m\n                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "#PARAMETRIC PROGRAMMING\n",
    "\n",
    "n_target = 20\n",
    "n_source = 10\n",
    "p = 40\n",
    "K = 5\n",
    "Ka = 3\n",
    "h = 30\n",
    "lamda = 0.03\n",
    "s_vector = [0,0,0,0,0,0,0,0,0,0]\n",
    "T = 5\n",
    "s = len(s_vector)\n",
    "CoRT_model = CoRT(alpha=lamda)\n",
    "p_values = []\n",
    "\n",
    "iteration = 100\n",
    "\n",
    "for step in range(iteration):\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-6, max_iter=500000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "    if len(active_indices) == 0:\n",
    "        print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "    Z_train_list = utils.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = utils.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "    L_CoRT, R_CoRT, Az = utils.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "    offset = p * len(similar_source_index)\n",
    "    Az_target_only = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "    while z_k < z_max:\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "        for val in Z_train_list:\n",
    "            if val[4] <= z_k:\n",
    "                l, r = utils.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                val[3] = l\n",
    "                val[4] = r\n",
    "        for val in Z_val_list:\n",
    "            if val[3] <= z_k:\n",
    "                l, r = utils.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "        if R_CoRT <= z_k:\n",
    "            L_CoRT, R_CoRT, Az = utils.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "        mn = z_max\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "        R_final = mn\n",
    "        # print(f\"[{z_k}] -> {mx, mn}\")\n",
    "        z_k = max(R_final, z_k) + 0.001\n",
    "        # print(f\"Processing {z_k}\")\n",
    "        # print(z_k)\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "    pivot_value = utils.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "    p_values.append(pivot_value)\n",
    "    print(f\"Processingggggggg {step, pivot_value}\")\n",
    "\n",
    "# Plot results\n",
    "plt.hist(p_values, density=True, bins=30, edgecolor='black')\n",
    "plt.title(\"p-value Distribution\")\n",
    "plt.xlabel(\"p-value\")\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    # etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "    # sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "    # truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "    # p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe3963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20\n",
      "-19.977075325557724\n",
      "-19.96677969144343\n",
      "-19.94816999930398\n",
      "-19.91821077638241\n",
      "-19.836963088167114\n",
      "-19.795253581985218\n",
      "-19.735575872166304\n",
      "-19.713655267160632\n",
      "-19.627850305625373\n",
      "-19.577300396345862\n",
      "-19.56285571927003\n",
      "-19.513852248027273\n",
      "-19.485827606873823\n",
      "-19.337161313946094\n",
      "-19.314966465025076\n",
      "-19.289149185907043\n",
      "-19.26802538880274\n",
      "-19.221449898365595\n",
      "-19.08209283579811\n",
      "-19.054388056848893\n",
      "-19.033029819896374\n",
      "-19.020809063562126\n",
      "-18.996957420521785\n",
      "-18.97623942892628\n",
      "-18.929078003770886\n",
      "-18.863524981995507\n",
      "-18.71885249704919\n",
      "-18.689572116966385\n",
      "-18.57855251945182\n",
      "-18.55022298583267\n",
      "-18.536325994761633\n",
      "-18.50210853579362\n",
      "-18.29773691698114\n",
      "-18.25951895667067\n",
      "-18.200864531367323\n",
      "-18.132356785298057\n",
      "-18.077577572485463\n",
      "-18.05007353654734\n",
      "-18.020454446697496\n",
      "-17.99784465456932\n",
      "-17.934463655558854\n",
      "-17.879931456522105\n",
      "-17.865611913609403\n",
      "-17.847987890967122\n",
      "-17.756400886775204\n",
      "-17.729061442430332\n",
      "-17.691766651684834\n",
      "-17.680630671153338\n",
      "-17.656548074921904\n",
      "-17.583480683314036\n",
      "-17.514889459427497\n",
      "-17.467794508595222\n",
      "-17.416939171900797\n",
      "-17.27775306022911\n",
      "-17.179507909609953\n",
      "-17.154938303164556\n",
      "-17.1048318115622\n",
      "-16.963797310844875\n",
      "-16.94926296426599\n",
      "-16.92917152824195\n",
      "-16.78774977057863\n",
      "-16.72116880817437\n",
      "-16.64275419810773\n",
      "-16.59946833975676\n",
      "-16.519207752987935\n",
      "-16.428360953438418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[143]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m mn = z_max\n\u001b[32m     50\u001b[39m Z_train_list = utils.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m Z_val_list = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_Z_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m L_CoRT, R_CoRT, Az = utils.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n\u001b[32m     53\u001b[39m offset = p * \u001b[38;5;28mlen\u001b[39m(similar_source_index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\Selective_Inference_For_CoRT\\File cua Nho\\utils.py:324\u001b[39m, in \u001b[36mget_Z_val\u001b[39m\u001b[34m(z_obs, folds, T, K, a_global, b_global, alpha_val, source_data)\u001b[39m\n\u001b[32m    322\u001b[39m source_data_k = source_data[k]\n\u001b[32m    323\u001b[39m X_aug_train, a_aug_train, b_aug_train = get_affine_params(X_target_train, train_indices, a_global, b_global, source_data_k)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m u_aug, v_aug = \u001b[43mget_u_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_aug_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_aug_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_aug_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m C2_aug, C1_aug, C0_aug = get_loss_coefs(a_base_val, b_base_val, u_aug, v_aug, X_val)\n\u001b[32m    327\u001b[39m A_dif = C2_aug - C2_base\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\Selective_Inference_For_CoRT\\File cua Nho\\utils.py:240\u001b[39m, in \u001b[36mget_u_v\u001b[39m\u001b[34m(X, a, b, z_obs, alpha_val)\u001b[39m\n\u001b[32m    238\u001b[39m y = a + b * z_obs\n\u001b[32m    239\u001b[39m clf = Lasso(alpha=alpha_val, fit_intercept=\u001b[38;5;28;01mFalse\u001b[39;00m, tol=\u001b[32m1e-8\u001b[39m, max_iter=\u001b[32m10000000\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m active_indices = [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, coef \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clf.coef_) \u001b[38;5;28;01mif\u001b[39;00m coef != \u001b[32m0\u001b[39m]\n\u001b[32m    243\u001b[39m inactive_indices = [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, coef \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clf.coef_) \u001b[38;5;28;01mif\u001b[39;00m coef == \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1123\u001b[39m, in \u001b[36mElasticNet.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1122\u001b[39m     this_Xy = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m _, this_coef, this_dual_gap, this_iter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[32m   1139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m coef_[k] = this_coef[:, \u001b[32m0\u001b[39m]\n\u001b[32m   1148\u001b[39m dual_gaps_[k] = this_dual_gap[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716\u001b[39m, in \u001b[36menet_path\u001b[39m\u001b[34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[39m\n\u001b[32m    701\u001b[39m     model = cd_fast.enet_coordinate_descent_gram(\n\u001b[32m    702\u001b[39m         coef_,\n\u001b[32m    703\u001b[39m         l1_reg,\n\u001b[32m   (...)\u001b[39m\u001b[32m    713\u001b[39m         do_screening,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     model = \u001b[43mcd_fast\u001b[49m\u001b[43m.\u001b[49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_screening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    731\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPrecompute should be one of True, False, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    732\u001b[39m         % precompute\n\u001b[32m    733\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# #PARAMETRIC PROGRAMMING\n",
    "\n",
    "# n_target = 20\n",
    "# n_source = 10\n",
    "# p = 40\n",
    "# K = 5\n",
    "# Ka = 3\n",
    "# h = 30\n",
    "# lamda = 0.03\n",
    "# s_vector = [0,0,0,0,0,0,0,0,0,0]\n",
    "# T = 5  \n",
    "# s = len(s_vector)\n",
    "# CoRT_model = CoRT(alpha=lamda)\n",
    "# p_values = []\n",
    "\n",
    "# iteration = 10\n",
    "\n",
    "# for step in range(iteration):\n",
    "#     target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "#     similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "#     X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "#     model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-8, max_iter=10000000)\n",
    "#     model.fit(X_combined, y_combined.ravel())\n",
    "#     beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "#     active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "#     if len(active_indices) == 0:\n",
    "#         print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     j = np.random.choice(len(active_indices))\n",
    "#     X_target = target_data[\"X\"]\n",
    "#     y_target = target_data[\"y\"]\n",
    "#     X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "#     etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "#     Sigma = np.eye(n_target)\n",
    "#     b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "#     a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "#     folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "#     z_k = -20\n",
    "#     z_max = 20\n",
    "    \n",
    "#     z_list = [z_k]\n",
    "#     Az_list = []\n",
    "#     while z_k < z_max:\n",
    "#         mn = z_max\n",
    "#         Z_train_list = utils.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "#         Z_val_list = utils.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "#         L_CoRT, R_CoRT, Az = utils.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "#         offset = p * len(similar_source_index)\n",
    "#         Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "#         Az_list.append(Az_target_current)\n",
    "#         print(z_k)\n",
    "#         if np.array_equal(active_indices, Az_target_current):\n",
    "#             print(f\"Dit con me may Hiep {step}\")\n",
    "#         for val in Z_train_list:\n",
    "#             mn = min(mn, val[4])\n",
    "#         for val in Z_val_list:\n",
    "#             mn = min(mn, val[3])\n",
    "#         mn = min(mn, R_CoRT)\n",
    "#         R_final = mn\n",
    "#         z_k = R_final + 0.01\n",
    "#         if (z_k >= z_max):\n",
    "#             z_list.append(z_max)\n",
    "#         else:\n",
    "#             z_list.append(z_k)\n",
    "#         # print(f\"Processing {z_k}\")\n",
    "\n",
    "#     pivot_value = utils.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "#     p_values.append(pivot_value)\n",
    "#     print(f\"Processing {step, pivot_value}\")\n",
    "\n",
    "# # Plot results\n",
    "# plt.hist(p_values, density=True, bins=30, edgecolor='black')\n",
    "# plt.title(\"p-value Distribution\")\n",
    "# plt.xlabel(\"p-value\")\n",
    "# plt.ylabel('Density')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#     # etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "#     # sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "#     # truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "#     # p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
