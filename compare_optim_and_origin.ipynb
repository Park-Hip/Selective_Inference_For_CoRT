{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834f96d5",
   "metadata": {},
   "source": [
    "## Test uniform original parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d608cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------START OPTIMIZED VERSION--------------------------------------------------\n",
      "optim_p_value[0]: 0.021917369883066747\n",
      "--------------------------------------------------START OPTIMIZED VERSION--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 145\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m update_val_needed:\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m Z_val_list:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         l, r, similar_source_index, cnt_vote, is_similar, oke = \u001b[43mparametric_optim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_Z_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilar_source_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnt_vote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_similar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m         val[\u001b[32m2\u001b[39m] = l\n\u001b[32m    147\u001b[39m         val[\u001b[32m3\u001b[39m] = r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\Selective_Inference_For_CoRT\\parametric_optim.py:390\u001b[39m, in \u001b[36mupdate_Z_val\u001b[39m\u001b[34m(val, z_obs, folds, T, K, a_global, b_global, alpha_val, source_data, similar_source, cnt_vote, is_similar)\u001b[39m\n\u001b[32m    387\u001b[39m train_indices = np.concatenate(train_indices_list) \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[32m    389\u001b[39m X_base_train, a_base_train, b_base_train = get_affine_params(X_target_train, train_indices, a_global, b_global)\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m u_base, v_base = \u001b[43mget_u_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m X_val = folds[t][\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    393\u001b[39m val_indices = fold_indices[t]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\Selective_Inference_For_CoRT\\parametric_optim.py:251\u001b[39m, in \u001b[36mget_u_v\u001b[39m\u001b[34m(X, a, b, z_obs, alpha_val)\u001b[39m\n\u001b[32m    249\u001b[39m y = a + b * z_obs\n\u001b[32m    250\u001b[39m clf = Lasso(alpha=alpha_val, fit_intercept=\u001b[38;5;28;01mFalse\u001b[39;00m, tol=\u001b[32m1e-10\u001b[39m, max_iter=\u001b[32m10000000\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m active_indices = [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, coef \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clf.coef_) \u001b[38;5;28;01mif\u001b[39;00m coef != \u001b[32m0\u001b[39m]\n\u001b[32m    254\u001b[39m inactive_indices = [idx \u001b[38;5;28;01mfor\u001b[39;00m idx, coef \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clf.coef_) \u001b[38;5;28;01mif\u001b[39;00m coef == \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1123\u001b[39m, in \u001b[36mElasticNet.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1122\u001b[39m     this_Xy = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m _, this_coef, this_dual_gap, this_iter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[32m   1139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m coef_[k] = this_coef[:, \u001b[32m0\u001b[39m]\n\u001b[32m   1148\u001b[39m dual_gaps_[k] = this_dual_gap[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716\u001b[39m, in \u001b[36menet_path\u001b[39m\u001b[34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[39m\n\u001b[32m    701\u001b[39m     model = cd_fast.enet_coordinate_descent_gram(\n\u001b[32m    702\u001b[39m         coef_,\n\u001b[32m    703\u001b[39m         l1_reg,\n\u001b[32m   (...)\u001b[39m\u001b[32m    713\u001b[39m         do_screening,\n\u001b[32m    714\u001b[39m     )\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     model = \u001b[43mcd_fast\u001b[49m\u001b[43m.\u001b[49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_screening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    731\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPrecompute should be one of True, False, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    732\u001b[39m         % precompute\n\u001b[32m    733\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "import oc\n",
    "from mpmath import mp\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(parametric_optim)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import copy\n",
    "\n",
    "n_target = 20\n",
    "n_source = 20\n",
    "p = 30\n",
    "K = 5\n",
    "Ka = 3\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "alpha = 0.05\n",
    "s_vector = [1] * 7\n",
    "T = 5\n",
    "s = len(s_vector)\n",
    "CoRT_model = CoRT(alpha=lamda)\n",
    "p_values = []\n",
    "iteration = 2\n",
    "oc_results_storage = []\n",
    "para_results_storage = []\n",
    "\n",
    "for step in range(iteration):\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "    initial_active_indices = active_indices\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "\n",
    "    selected_feature_index = active_indices[j]\n",
    "\n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    tn_sigma = mp.mpf((np.sqrt(etaj.T @ Sigma @ etaj)).item())\n",
    "    z_k = -20 \n",
    "    z_max = 20 \n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list, similar_source_index, cnt_vote, is_similar = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    # similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "\n",
    "    print(\"-\"*50 + \"START OPTIMIZED VERSION\" + \"-\"*50)\n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "    matched_active_set = None\n",
    "\n",
    "    stopper = \"empty\"\n",
    "    while z_k < z_max:\n",
    "        current_num_sources = len(similar_source_index)\n",
    "        offset = p * current_num_sources\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        mn = z_max\n",
    "        stopper = \"MAX\"\n",
    "        # print(z_k)\n",
    "\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "            break\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True   \n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            \n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r, similar_source_index, cnt_vote, is_similar, oke = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data, similar_source_index, cnt_vote, is_similar)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "                if oke == True:\n",
    "                    update_cort_needed = True\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    z_interval = []\n",
    "    for i in range(len(Az_list)):\n",
    "        if np.array_equal(active_indices, Az_list[i]):\n",
    "                z_interval.append([z_list[i], z_list[i+1] - 1e-10]) \n",
    "\n",
    "    new_z_interval = []\n",
    "    for interval in z_interval:\n",
    "        if len(new_z_interval) == 0:\n",
    "            new_z_interval.append(interval)\n",
    "        else:\n",
    "            dif = abs(interval[0] - new_z_interval[-1][1])\n",
    "            if dif < 0.001:\n",
    "                new_z_interval[-1][1] = interval[1]\n",
    "            else:\n",
    "                new_z_interval.append(interval)\n",
    "    optim_z_interval = new_z_interval\n",
    "\n",
    "    is_z_obs_in_intervals = False\n",
    "    for i, interval in enumerate(optim_z_interval):\n",
    "        if interval[0] <= etajTy <= interval[1]:\n",
    "            is_z_obs_in_intervals = True\n",
    "            break\n",
    "\n",
    "    if is_z_obs_in_intervals == False:\n",
    "        print(f\" WARNING: z_obs is not in the intervals:\\nz_obs: {etajTy:.5f}\\nIntervals:{optim_z_interval}\")\n",
    "\n",
    "    optim_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "\n",
    "    if optim_p_value == 0:\n",
    "        print(\" WARNING: p-value is 0\")\n",
    "    if optim_p_value is None:\n",
    "        print(\" WARNING: p-value is None\")\n",
    "    print(f\"optim_p_value[{step}]: {optim_p_value}\")\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_results_storage.append({\n",
    "        \"p_value\": optim_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    })\n",
    "    p_values.append(optim_p_value)\n",
    "plt.hist(p_values, bins=10, edgecolor='black', density=True)\n",
    "plt.title(f\"Uniform - {iteration} iterations\")\n",
    "plt.xlabel(\"p-value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------START OPTIMIZED VERSION--------------------------------------------------\n",
      "optim_p_value[0]: 0.3949827704852815\n",
      "Parametric FPR: 0.0000 (Target: 0.05)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 206\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParametric FPR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpara_fpr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    205\u001b[39m para_true_positives = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m para_is_signal_cases \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[33m'\u001b[39m\u001b[33mp_value\u001b[39m\u001b[33m'\u001b[39m] <= alpha)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m para_tpr = \u001b[43mpara_true_positives\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpara_is_signal_cases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParametric TPR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpara_tpr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "import oc\n",
    "from mpmath import mp\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(parametric_optim)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import copy\n",
    "\n",
    "n_target = 10\n",
    "n_source = 10\n",
    "p = 15\n",
    "K = 5\n",
    "Ka = 3\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "alpha = 0.05\n",
    "s_vector = [1] * 4\n",
    "T = 5\n",
    "s = len(s_vector)\n",
    "CoRT_model = CoRT(alpha=lamda)\n",
    "p_values = []\n",
    "iteration = 1\n",
    "oc_results_storage = []\n",
    "para_results_storage = []\n",
    "\n",
    "for step in range(iteration):\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "    initial_active_indices = active_indices\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "\n",
    "    selected_feature_index = active_indices[j]\n",
    "\n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    tn_sigma = mp.mpf((np.sqrt(etaj.T @ Sigma @ etaj)).item())\n",
    "    z_k = -20 \n",
    "    z_max = 20 \n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list, similar_source_index, cnt_vote, is_similar = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    # similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "\n",
    "    print(\"-\"*50 + \"START OPTIMIZED VERSION\" + \"-\"*50)\n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "    matched_active_set = None\n",
    "\n",
    "    stopper = \"empty\"\n",
    "    while z_k < z_max:\n",
    "        current_num_sources = len(similar_source_index)\n",
    "        offset = p * current_num_sources\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        mn = z_max\n",
    "        stopper = \"MAX\"\n",
    "        # print(z_k)\n",
    "\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "            break\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True   \n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            \n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r, similar_source_index, cnt_vote, is_similar, oke = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data, similar_source_index, cnt_vote, is_similar)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "                if oke == True:\n",
    "                    update_cort_needed = True\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_index, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    z_interval = []\n",
    "    for i in range(len(Az_list)):\n",
    "        if np.array_equal(active_indices, Az_list[i]):\n",
    "                z_interval.append([z_list[i], z_list[i+1] - 1e-10]) \n",
    "\n",
    "    new_z_interval = []\n",
    "    for interval in z_interval:\n",
    "        if len(new_z_interval) == 0:\n",
    "            new_z_interval.append(interval)\n",
    "        else:\n",
    "            dif = abs(interval[0] - new_z_interval[-1][1])\n",
    "            if dif < 0.001:\n",
    "                new_z_interval[-1][1] = interval[1]\n",
    "            else:\n",
    "                new_z_interval.append(interval)\n",
    "    optim_z_interval = new_z_interval\n",
    "\n",
    "    is_z_obs_in_intervals = False\n",
    "    for i, interval in enumerate(optim_z_interval):\n",
    "        if interval[0] <= etajTy <= interval[1]:\n",
    "            is_z_obs_in_intervals = True\n",
    "            break\n",
    "\n",
    "    if is_z_obs_in_intervals == False:\n",
    "        print(f\" WARNING: z_obs is not in the intervals:\\nz_obs: {etajTy:.5f}\\nIntervals:{optim_z_interval}\")\n",
    "\n",
    "    optim_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "\n",
    "    if optim_p_value == 0:\n",
    "        print(\" WARNING: p-value is 0\")\n",
    "    if optim_p_value is None:\n",
    "        print(\" WARNING: p-value is None\")\n",
    "    print(f\"optim_p_value[{step}]: {optim_p_value}\")\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_results_storage.append({\n",
    "        \"p_value\": optim_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    })\n",
    "\n",
    "    \n",
    "# Show parametric result \n",
    "para_is_signal_cases = [r for r in para_results_storage if r['is_signal']]\n",
    "para_not_signal_cases = [r for r in para_results_storage if not r['is_signal']]\n",
    "\n",
    "para_false_positives = sum(1 for c in para_not_signal_cases if c['p_value'] <= alpha)\n",
    "para_fpr = para_false_positives / len(para_not_signal_cases)\n",
    "print(f\"Parametric FPR: {para_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "para_true_positives = sum(1 for r in para_is_signal_cases if r['p_value'] <= alpha)\n",
    "para_tpr = para_true_positives / len(para_is_signal_cases)\n",
    "print(f\"Parametric TPR: {para_tpr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
