{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95462a02",
   "metadata": {},
   "source": [
    "## Use original parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ac0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iter: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 166\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m update_val_needed:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m Z_val_list:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         l, r = \u001b[43mparametric_optim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_Z_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m         val[\u001b[32m2\u001b[39m] = l\n\u001b[32m    168\u001b[39m         val[\u001b[32m3\u001b[39m] = r\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\CORT2\\parametric_optim.py:368\u001b[39m, in \u001b[36mupdate_Z_val\u001b[39m\u001b[34m(val, z_obs, folds, T, K, a_global, b_global, alpha_val, source_data)\u001b[39m\n\u001b[32m    365\u001b[39m train_indices = np.concatenate(train_indices_list) \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[32m    367\u001b[39m X_base_train, a_base_train, b_base_train = get_affine_params(X_target_train, train_indices, a_global, b_global)\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m u_base, v_base = \u001b[43mget_u_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    370\u001b[39m X_val = folds[t][\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    371\u001b[39m val_indices = fold_indices[t]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\CORT2\\parametric_optim.py:268\u001b[39m, in \u001b[36mget_u_v\u001b[39m\u001b[34m(X, a, b, z_obs, alpha_val)\u001b[39m\n\u001b[32m    265\u001b[39m lambda_val = alpha_val * n\n\u001b[32m    267\u001b[39m u_active = np.linalg.pinv(X_M.T @ X_M) @ (X_M.T @ a - lambda_val * s_M)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m v_active = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_M\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_M\u001b[49m\u001b[43m)\u001b[49m @ (X_M.T @ b)\n\u001b[32m    270\u001b[39m u_full[active_indices] = u_active\n\u001b[32m    271\u001b[39m v_full[active_indices] = v_active\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\CORT2\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2281\u001b[39m, in \u001b[36mpinv\u001b[39m\u001b[34m(a, rcond, hermitian, rtol)\u001b[39m\n\u001b[32m   2279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap(res)\n\u001b[32m   2280\u001b[39m a = a.conjugate()\n\u001b[32m-> \u001b[39m\u001b[32m2281\u001b[39m u, s, vt = \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhermitian\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhermitian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2283\u001b[39m \u001b[38;5;66;03m# discard small singular values\u001b[39;00m\n\u001b[32m   2284\u001b[39m cutoff = rcond[..., newaxis] * amax(s, axis=-\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Data Science Project\\CORT2\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:1862\u001b[39m, in \u001b[36msvd\u001b[39m\u001b[34m(a, full_matrices, compute_uv, hermitian)\u001b[39m\n\u001b[32m   1858\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->DdD\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->ddd\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1859\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_svd_nonconvergence,\n\u001b[32m   1860\u001b[39m               invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m, over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1861\u001b[39m               under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1862\u001b[39m     u, s, vh = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1863\u001b[39m u = u.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1864\u001b[39m s = s.astype(_realType(result_t), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import utils\n",
    "from CoRT_builder import CoRT\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import oc\n",
    "import parametric_optim\n",
    "importlib.reload(utils)\n",
    "importlib.reload(oc)\n",
    "\n",
    "n_target = 30\n",
    "n_source = 10\n",
    "p = 10\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "s_vector = [1,1,1]\n",
    "T = 3\n",
    "s = len(s_vector)\n",
    "CoRT_model = CoRT(alpha=lamda)\n",
    "oc_results_storage = []\n",
    "para_results_storage = []\n",
    "alpha = 0.05\n",
    "iteration = 200\n",
    "\n",
    "for i in range(iteration):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"Processing iter: {i}\")\n",
    "\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "    initial_active_indices = active_indices\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "\n",
    "    selected_feature_index = active_indices[j]\n",
    "\n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    # OVER-CONDITIONING\n",
    "    L_train, R_train = oc.get_Z_train(etajTy, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    L_val, R_val = oc.get_Z_val(folds, T, K, a_global, b_global, etajTy, lamda, source_data)\n",
    "    L_CoRT, R_CoRT, Az = oc.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, etajTy)\n",
    "\n",
    "    L_final, R_final = oc.combine_Z(L_train, R_train, L_val, R_val, L_CoRT, R_CoRT)\n",
    "\n",
    "    etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "    sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "    truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "    oc_p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)\n",
    "\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    oc_results_storage.append({\n",
    "            \"p_value\": oc_p_value,\n",
    "            \"is_signal\": is_signal,\n",
    "            \"feature_idx\": selected_feature_index\n",
    "    })\n",
    "\n",
    "    # PARAMETRIC\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    Az_target_only = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "\n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "\n",
    "    step_count = 0\n",
    "    matched_active_set = None\n",
    "\n",
    "    stopper = \"empty\"\n",
    "    while z_k < z_max:\n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "        \n",
    "        mn = z_max\n",
    "        stopper = \"MAX\"\n",
    "\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            print(\"[WARNING] R_final is before zk\")\n",
    "            z_k += 0.001\n",
    "\n",
    "        z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "            break\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True   \n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    para_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "\n",
    "    if para_p_value == 0:\n",
    "        print(\" WARNING: p-value is 0\")\n",
    "    if para_p_value is None:\n",
    "        print(\" WARNING: p-value is None\")\n",
    "\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_results_storage.append({\n",
    "        \"p_value\": para_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    })\n",
    "\n",
    "# Show Over-conditioning result\n",
    "oc_is_signal_cases = [r for r in oc_results_storage if r['is_signal']]\n",
    "oc_not_signal_cases = [r for r in oc_results_storage if not r['is_signal']]\n",
    "\n",
    "oc_false_positives = sum(1 for c in oc_not_signal_cases if c['p_value'] <= alpha)\n",
    "oc_fpr = oc_false_positives / len(oc_not_signal_cases)\n",
    "print(f\"Over-conditioning FPR: {oc_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "oc_true_positives = sum(1 for r in oc_is_signal_cases if r['p_value'] <= alpha)\n",
    "oc_tpr = oc_true_positives / len(oc_is_signal_cases)\n",
    "print(f\"Over-conditioning TPR: {oc_tpr:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show parametric result \n",
    "para_is_signal_cases = [r for r in para_results_storage if r['is_signal']]\n",
    "para_not_signal_cases = [r for r in para_results_storage if not r['is_signal']]\n",
    "\n",
    "para_false_positives = sum(1 for c in para_not_signal_cases if c['p_value'] <= alpha)\n",
    "para_fpr = para_false_positives / len(para_not_signal_cases)\n",
    "print(f\"Parametric FPR: {para_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "para_true_positives = sum(1 for r in para_is_signal_cases if r['p_value'] <= alpha)\n",
    "para_tpr = para_true_positives / len(para_is_signal_cases)\n",
    "print(f\"Parametric TPR: {para_tpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b502384",
   "metadata": {},
   "source": [
    "## Use optimized parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iter: 0\n",
      "Processing iter: 20\n",
      "Processing iter: 40\n",
      "Processing iter: 60\n",
      "Processing iter: 80\n",
      "Processing iter: 100\n",
      "Processing iter: 120\n",
      "Processing iter: 140\n",
      "Processing iter: 160\n",
      "Processing iter: 180\n",
      "Processing iter: 200\n",
      "Processing iter: 220\n",
      "Processing iter: 240\n",
      "Processing iter: 260\n",
      "Processing iter: 280\n",
      "Processing iter: 300\n",
      "Processing iter: 320\n",
      "Processing iter: 340\n",
      "Processing iter: 360\n",
      "Processing iter: 380\n",
      "Processing iter: 400\n",
      "Processing iter: 420\n",
      "Processing iter: 440\n",
      "Processing iter: 460\n",
      "Processing iter: 480\n",
      "Processing iter: 500\n",
      "Processing iter: 520\n",
      "Processing iter: 540\n",
      "Processing iter: 560\n",
      "Processing iter: 580\n",
      "Processing iter: 600\n",
      "Processing iter: 620\n",
      "Processing iter: 640\n",
      "[WARNING] R_final is before zk\n",
      "Processing iter: 660\n",
      "Processing iter: 680\n",
      "Processing iter: 700\n",
      "[WARNING] R_final is before zk\n",
      "Processing iter: 720\n",
      "Processing iter: 740\n",
      "Processing iter: 760\n",
      "[WARNING] R_final is before zk\n",
      "Processing iter: 780\n",
      "Processing iter: 800\n",
      "[WARNING] R_final is before zk\n",
      "Processing iter: 820\n",
      "Processing iter: 840\n",
      "Processing iter: 860\n",
      "Processing iter: 880\n",
      "Processing iter: 900\n",
      "Processing iter: 920\n",
      "Processing iter: 940\n",
      "Processing iter: 960\n",
      "Processing iter: 980\n",
      "Over-conditioning FPR: 0.0561 (Target: 0.05)\n",
      "Over-conditioning TPR: 0.1863\n",
      "==================================================\n",
      "Parametric FPR: 0.0619 (Target: 0.05)\n",
      "Parametric TPR: 0.7495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import utils\n",
    "from CoRT_builder import CoRT\n",
    "import parametric_optim\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import oc\n",
    "importlib.reload(utils)\n",
    "importlib.reload(oc)\n",
    "\n",
    "n_target = 30\n",
    "n_source = 10\n",
    "p = 10\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "s_vector = [1] * 3\n",
    "T = 3\n",
    "s = len(s_vector)\n",
    "CoRT_model = CoRT(alpha=lamda)\n",
    "alpha = 0.05\n",
    "iteration = 1000\n",
    "\n",
    "oc_results_storage = []\n",
    "para_results_storage = []\n",
    "\n",
    "for i in range(iteration):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processing iter: {i}\")\n",
    "\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "    initial_active_indices = active_indices\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "\n",
    "    selected_feature_index = active_indices[j]\n",
    "\n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    # OVER-CONDITIONING\n",
    "    L_train, R_train = oc.get_Z_train(etajTy, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    L_val, R_val = oc.get_Z_val(folds, T, K, a_global, b_global, etajTy, lamda, source_data)\n",
    "    L_CoRT, R_CoRT, Az = oc.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, etajTy)\n",
    "\n",
    "    L_final, R_final = oc.combine_Z(L_train, R_train, L_val, R_val, L_CoRT, R_CoRT)\n",
    "\n",
    "    etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "    sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "    truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "    oc_p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)\n",
    "\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    oc_results_storage.append({\n",
    "            \"p_value\": oc_p_value,\n",
    "            \"is_signal\": is_signal,\n",
    "            \"feature_idx\": selected_feature_index\n",
    "    })\n",
    "\n",
    "    # PARAMETRIC\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    Az_target_only = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "\n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "    matched_active_set = None\n",
    "\n",
    "    stopper = \"empty\"\n",
    "    while z_k < z_max:\n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "        \n",
    "        mn = z_max\n",
    "        stopper = \"MAX\"\n",
    "\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            print(\"[WARNING] R_final is before zk\")\n",
    "            z_k += 0.001\n",
    "\n",
    "        z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "            break\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True   \n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    para_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "\n",
    "    if para_p_value == 0:\n",
    "        print(\" WARNING: p-value is 0\")\n",
    "    if para_p_value is None:\n",
    "        print(\" WARNING: p-value is None\")\n",
    "\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_results_storage.append({\n",
    "        \"p_value\": para_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    })\n",
    "\n",
    "# Show Over-conditioning result\n",
    "oc_is_signal_cases = [r for r in oc_results_storage if r['is_signal']]\n",
    "oc_not_signal_cases = [r for r in oc_results_storage if not r['is_signal']]\n",
    "\n",
    "oc_false_positives = sum(1 for c in oc_not_signal_cases if c['p_value'] <= alpha)\n",
    "oc_fpr = oc_false_positives / len(oc_not_signal_cases)\n",
    "print(f\"Over-conditioning FPR: {oc_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "oc_true_positives = sum(1 for r in oc_is_signal_cases if r['p_value'] <= alpha)\n",
    "oc_tpr = oc_true_positives / len(oc_is_signal_cases)\n",
    "print(f\"Over-conditioning TPR: {oc_tpr:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show parametric result \n",
    "para_is_signal_cases = [r for r in para_results_storage if r['is_signal']]\n",
    "para_not_signal_cases = [r for r in para_results_storage if not r['is_signal']]\n",
    "\n",
    "para_false_positives = sum(1 for c in para_not_signal_cases if c['p_value'] <= alpha)\n",
    "para_fpr = para_false_positives / len(para_not_signal_cases)\n",
    "print(f\"Parametric FPR: {para_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "para_true_positives = sum(1 for r in para_is_signal_cases if r['p_value'] <= alpha)\n",
    "para_tpr = para_true_positives / len(para_is_signal_cases)\n",
    "print(f\"Parametric TPR: {para_tpr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
