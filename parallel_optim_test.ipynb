{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511e1a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1000 iterations in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ~~~~^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Legion\\AppData\\Local\\Temp\\ipykernel_9040\\2572238728.py\", line 114, in run_single_trial\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 198\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m iterations in parallel...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# Run in parallel using all available cores (n_jobs=-1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_single_trial\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# print(\"\\n\\n\")\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# print(\"-\" * 50 + \"OVER-CONDITIONING\" +\"-\" * 50)\u001b[39;00m\n\u001b[32m    205\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# para_tpr = para_true_positives / len(para_is_signal_cases)\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# print(f\"Parametric TPR: {para_tpr:.4f}\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Legion\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed \n",
    "import oc\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "\n",
    "def run_single_trial(seed, n_target, n_source, p, K, Ka, h, lamda, s_vector, T):\n",
    "    \"\"\"\n",
    "    Runs a single simulation iteration.\n",
    "    \"\"\"\n",
    "    # Set unique seed for this parallel worker\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    s = len(s_vector)\n",
    "    CoRT_model = CoRT(alpha=lamda)\n",
    "    \n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.sort(np.array([i for i, b in enumerate(beta_hat_target) if b != 0]))\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        return None \n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "    selected_feature_index = active_indices[j]\n",
    "    \n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "    \n",
    "    # OVER-CONDITIONING\n",
    "    L_train, R_train = oc.get_Z_train(etajTy, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    L_val, R_val = oc.get_Z_val(folds, T, K, a_global, b_global, etajTy, lamda, source_data)\n",
    "    L_CoRT, R_CoRT, Az = oc.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, etajTy)\n",
    "\n",
    "    L_final, R_final = oc.combine_Z(L_train, R_train, L_val, R_val, L_CoRT, R_CoRT)\n",
    "\n",
    "    etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "    sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "    truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "    oc_p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)\n",
    "\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    oc_result_dict = {\n",
    "            \"p_value\": oc_p_value,\n",
    "            \"is_signal\": is_signal,\n",
    "            \"feature_idx\": selected_feature_index\n",
    "    }\n",
    "\n",
    "    # Parametric\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    \n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "\n",
    "    # 5. Path Following Loop\n",
    "    step_count = 0\n",
    "    matched_active_set = None\n",
    "    \n",
    "    while z_k < z_max:\n",
    "        step_count += 1\n",
    "        \n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "        \n",
    "        # [FIX] Sort the active set found along the path\n",
    "        Az_target_current = np.sort(np.array([idx - offset for idx in Az if idx >= offset]))\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        mn = z_max\n",
    "        stopper = None\n",
    "\n",
    "        # Check Train Boundaries\n",
    "        for val in Z_train_list:\n",
    "            if mn - val[4] > 1e-9:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        # Check Val Boundaries\n",
    "        for val in Z_val_list:\n",
    "            if mn - val[3] > 1e-9:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        # Check CoRT Boundaries\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            z_k += 1e-5\n",
    "        else:\n",
    "            z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "    \n",
    "    para_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_result_dict = {\n",
    "        \"p_value\": para_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    }\n",
    "    \n",
    "    return (oc_result_dict , para_result_dict)\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution Block\n",
    "# ==========================================\n",
    "n_target = 30\n",
    "n_source = 10\n",
    "p = 10\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "alpha = 0.05\n",
    "s_vector = [1] * 1\n",
    "T = 3\n",
    "iteration = 1000\n",
    "\n",
    "print(f\"Starting {iteration} iterations in parallel...\")\n",
    "\n",
    "# Run in parallel using all available cores (n_jobs=-1)\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_single_trial)(i, n_target, n_source, p, K, Ka, h, lamda, s_vector, T) \n",
    "    for i in range(iteration)\n",
    ")\n",
    "\n",
    "# print(\"\\n\\n\")\n",
    "# print(\"-\" * 50 + \"OVER-CONDITIONING\" +\"-\" * 50)\n",
    "\n",
    "# oc_results_storage = [res[0] for res in results if res is not None]\n",
    "# para_results_storage = [res[1] for res in results if res is not None]\n",
    "\n",
    "# oc_is_signal_cases = [r for r in oc_results_storage if r['is_signal']]\n",
    "# oc_not_signal_cases = [r for r in oc_results_storage if not r['is_signal']]\n",
    "\n",
    "# oc_false_positives = sum(1 for c in oc_not_signal_cases if c['p_value'] <= alpha)\n",
    "# oc_fpr = oc_false_positives / len(oc_not_signal_cases)\n",
    "# print(f\"Over-conditioning FPR: {oc_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "# oc_true_positives = sum(1 for r in oc_is_signal_cases if r['p_value'] <= alpha)\n",
    "# oc_tpr = oc_true_positives / len(oc_is_signal_cases)\n",
    "# print(f\"Over-conditioning TPR: {oc_tpr:.4f}\")\n",
    "# print(\"\\n\\n\")\n",
    "\n",
    "# # Show parametric result \n",
    "# print(\"-\" * 50 + \"PARAMETRIC\" + \"-\" * 50)\n",
    "# para_is_signal_cases = [r for r in para_results_storage if r['is_signal']]\n",
    "# para_not_signal_cases = [r for r in para_results_storage if not r['is_signal']]\n",
    "\n",
    "# para_false_positives = sum(1 for c in para_not_signal_cases if c['p_value'] <= alpha)\n",
    "# para_fpr = para_false_positives / len(para_not_signal_cases)\n",
    "# print(f\"Parametric FPR: {para_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "# para_true_positives = sum(1 for r in para_is_signal_cases if r['p_value'] <= alpha)\n",
    "# para_tpr = para_true_positives / len(para_is_signal_cases)\n",
    "# print(f\"Parametric TPR: {para_tpr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
