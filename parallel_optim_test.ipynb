{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e1a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1000 iterations in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 497 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 637 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 674 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 713 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 793 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 877 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 920 tasks      | elapsed:  3.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------OVER-CONDITIONING--------------------------------------------------\n",
      "Over-conditioning FPR: 0.0460 (Target: 0.05)\n",
      "Over-conditioning TPR: 0.2308\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------PARAMETRIC--------------------------------------------------\n",
      "Parametric FPR: 0.0509 (Target: 0.05)\n",
      "Parametric TPR: 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.5min finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed \n",
    "import oc\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "\n",
    "def run_single_trial(seed, n_target, n_source, p, K, Ka, h, lamda, s_vector, T):\n",
    "    \"\"\"\n",
    "    Runs a single simulation iteration.\n",
    "    \"\"\"\n",
    "    # Set unique seed for this parallel worker\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    s = len(s_vector)\n",
    "    CoRT_model = CoRT(alpha=lamda)\n",
    "    \n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.sort(np.array([i for i, b in enumerate(beta_hat_target) if b != 0]))\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        return None \n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "    selected_feature_index = active_indices[j]\n",
    "    \n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "    \n",
    "    # OVER-CONDITIONING\n",
    "    L_train, R_train = oc.get_Z_train(etajTy, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    L_val, R_val = oc.get_Z_val(folds, T, K, a_global, b_global, etajTy, lamda, source_data)\n",
    "    L_CoRT, R_CoRT, Az = oc.get_Z_CoRT(X_combined, similar_source_index, lamda, a_global, b_global, source_data, etajTy)\n",
    "\n",
    "    L_final, R_final = oc.combine_Z(L_train, R_train, L_val, R_val, L_CoRT, R_CoRT)\n",
    "\n",
    "    etaT_sigma_eta = (etaj.T @ Sigma @ etaj).item()\n",
    "    sigma_z = np.sqrt(etaT_sigma_eta)\n",
    "    truncated_cdf = utils.computed_truncated_cdf(L_final, R_final, etajTy, 0, sigma_z)\n",
    "    oc_p_value = 2 * min(truncated_cdf, 1 - truncated_cdf)\n",
    "\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    oc_result_dict = {\n",
    "            \"p_value\": oc_p_value,\n",
    "            \"is_signal\": is_signal,\n",
    "            \"feature_idx\": selected_feature_index\n",
    "    }\n",
    "\n",
    "    # Parametric\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    \n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "\n",
    "    # 5. Path Following Loop\n",
    "    step_count = 0\n",
    "    matched_active_set = None\n",
    "    \n",
    "    while z_k < z_max:\n",
    "        step_count += 1\n",
    "        \n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "        \n",
    "        # [FIX] Sort the active set found along the path\n",
    "        Az_target_current = np.sort(np.array([idx - offset for idx in Az if idx >= offset]))\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        mn = z_max\n",
    "        stopper = None\n",
    "\n",
    "        # Check Train Boundaries\n",
    "        for val in Z_train_list:\n",
    "            if mn - val[4] > 1e-9:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        # Check Val Boundaries\n",
    "        for val in Z_val_list:\n",
    "            if mn - val[3] > 1e-9:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        # Check CoRT Boundaries\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            z_k += 1e-5\n",
    "        else:\n",
    "            z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "    \n",
    "    para_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_result_dict = {\n",
    "        \"p_value\": para_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    }\n",
    "    \n",
    "    return (oc_result_dict , para_result_dict)\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution Block\n",
    "# ==========================================\n",
    "n_target = 30\n",
    "n_source = 10\n",
    "p = 10\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "alpha = 0.05\n",
    "s_vector = [1] * 1\n",
    "T = 3\n",
    "iteration = 1000\n",
    "\n",
    "print(f\"Starting {iteration} iterations in parallel...\")\n",
    "\n",
    "# Run in parallel using all available cores (n_jobs=-1)\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_single_trial)(i, n_target, n_source, p, K, Ka, h, lamda, s_vector, T) \n",
    "    for i in range(iteration)\n",
    ")\n",
    "\n",
    "# print(\"\\n\\n\")\n",
    "# print(\"-\" * 50 + \"OVER-CONDITIONING\" +\"-\" * 50)\n",
    "\n",
    "# oc_results_storage = [res[0] for res in results if res is not None]\n",
    "# para_results_storage = [res[1] for res in results if res is not None]\n",
    "\n",
    "# oc_is_signal_cases = [r for r in oc_results_storage if r['is_signal']]\n",
    "# oc_not_signal_cases = [r for r in oc_results_storage if not r['is_signal']]\n",
    "\n",
    "# oc_false_positives = sum(1 for c in oc_not_signal_cases if c['p_value'] <= alpha)\n",
    "# oc_fpr = oc_false_positives / len(oc_not_signal_cases)\n",
    "# print(f\"Over-conditioning FPR: {oc_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "# oc_true_positives = sum(1 for r in oc_is_signal_cases if r['p_value'] <= alpha)\n",
    "# oc_tpr = oc_true_positives / len(oc_is_signal_cases)\n",
    "# print(f\"Over-conditioning TPR: {oc_tpr:.4f}\")\n",
    "# print(\"\\n\\n\")\n",
    "\n",
    "# # Show parametric result \n",
    "# print(\"-\" * 50 + \"PARAMETRIC\" + \"-\" * 50)\n",
    "# para_is_signal_cases = [r for r in para_results_storage if r['is_signal']]\n",
    "# para_not_signal_cases = [r for r in para_results_storage if not r['is_signal']]\n",
    "\n",
    "# para_false_positives = sum(1 for c in para_not_signal_cases if c['p_value'] <= alpha)\n",
    "# para_fpr = para_false_positives / len(para_not_signal_cases)\n",
    "# print(f\"Parametric FPR: {para_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "# para_true_positives = sum(1 for r in para_is_signal_cases if r['p_value'] <= alpha)\n",
    "# para_tpr = para_true_positives / len(para_is_signal_cases)\n",
    "# print(f\"Parametric TPR: {para_tpr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
