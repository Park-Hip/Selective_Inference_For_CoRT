{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f352fd6d",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(parametric_optim)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import copy\n",
    "\n",
    "n_target = 50\n",
    "n_source = 10\n",
    "p = 50\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.05\n",
    "s_vector = [0,0,0,0,0,0,0,0,0,0]\n",
    "T = 5\n",
    "s = len(s_vector)\n",
    "CoRT_model = CoRT(alpha=lamda)\n",
    "p_values = []\n",
    "\n",
    "iteration = 10\n",
    "\n",
    "for step in range(iteration):\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.array([i for i, b in enumerate(beta_hat_target) if b != 0])\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        print(f\"Iteration {iter}: Lasso selected no features. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "\n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    Az_target_only = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "\n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(\"Initialization\")\n",
    "    print(f\"Initial similar source index: {similar_source_index}\")\n",
    "    print(f\"z_obs: {etajTy:.5f}\")\n",
    "\n",
    "    print(f\"Initial Z_train_list: {Z_train_list}\")\n",
    "    print(f\"Initial Z_val_list : {Z_val_list}\")\n",
    "    print(f\"Initial Cort interval: {L_CoRT, R_CoRT}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    step_count = 0\n",
    "    stopper = \"empty\"\n",
    "    matched_active_set = None\n",
    "\n",
    "    while z_k < z_max:\n",
    "        step_count += 1\n",
    "        print(f\"zk at step {step_count}: {z_k:.5f}\")\n",
    "        print(f\"similar source current: {similar_source_current}\")\n",
    "\n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        # print(f\"Current Az target: {Az_target_current}\")\n",
    "\n",
    "        old_Z_train_list = copy.deepcopy(Z_train_list)\n",
    "        old_Z_val_list = copy.deepcopy(Z_val_list)\n",
    "        old_L_CoRT, old_R_CoRT = L_CoRT, R_CoRT\n",
    "        \n",
    "        mn = z_max\n",
    "        stopper = None\n",
    "\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = f\"TRAIN[type={val[0]}][t={val[1]}][k={val[2]}][L={val[3]:.5f}][R={val[4]:.5f}]\"\n",
    "\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = f\"VAL[t={val[0]}][k={val[1]}][L={val[2]:.5f}][R={val[3]:.5f}]\"\n",
    "\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = f\"CORT[{L_CoRT:.5f}, {R_CoRT:.5f}]\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            print(\"[WARNING] R_final is before zk\")\n",
    "            z_k += 0.001\n",
    "\n",
    "        z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if \"TRAIN\" in stopper:\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True   \n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif \"VAL\" in stopper:\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif \"CORT\" in stopper:\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "        print(f\"==UPDATE==\")\n",
    "        for i, val in enumerate(Z_train_list):\n",
    "            if val != old_Z_train_list[i]:\n",
    "                print(f\"OLD: {old_Z_train_list[i]}\\nNEW: {val}\")\n",
    "\n",
    "        for i, val in enumerate(Z_val_list):\n",
    "            if val != old_Z_val_list[i]:\n",
    "                print(f\"OLD: {old_Z_val_list[i]}\\nNEW: {val}\")\n",
    "\n",
    "        if old_L_CoRT != L_CoRT or old_R_CoRT != R_CoRT:\n",
    "            print(f\"OLD: ({old_L_CoRT}, {old_R_CoRT})\\nNEW: ({L_CoRT}, {R_CoRT})\")\n",
    "\n",
    "        print(f\"Stopper: {stopper}\")\n",
    "\n",
    "        if np.array_equal(Az_target_current, active_indices):\n",
    "            print(f\"Detected current active target match with the observed at zk: {z_k}\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "    z_interval = []\n",
    "    for i in range(len(Az_list)):\n",
    "        if np.array_equal(active_indices, Az_list[i]):\n",
    "                z_interval.append([z_list[i], z_list[i+1]]) \n",
    "\n",
    "    new_z_interval = []\n",
    "    for interval in z_interval:\n",
    "        if len(new_z_interval) == 0:\n",
    "            new_z_interval.append(interval)\n",
    "        else:\n",
    "            dif = abs(interval[0] - new_z_interval[-1][1])\n",
    "            if dif < 0.001:\n",
    "                new_z_interval[-1][1] = interval[1]\n",
    "            else:\n",
    "                new_z_interval.append(interval)\n",
    "    z_interval = new_z_interval\n",
    "    \n",
    "    print(f\"z_obs: {etajTy:.5f}\")\n",
    "    print(f\"{len(z_interval)} intervals found: {z_interval}\")\n",
    "\n",
    "    is_z_obs_in_intervals = False\n",
    "    for i, interval in enumerate(z_interval):\n",
    "        if interval[0] <= etajTy <= interval[1]:\n",
    "            is_z_obs_in_intervals = True\n",
    "            break\n",
    "\n",
    "    if is_z_obs_in_intervals == False:\n",
    "        print(f\" WARNING: z_obs is not in the intervals:\\nz_obs: {etajTy:.5f}\\nIntervals:{z_interval}\")\n",
    "    else: \n",
    "        print(\"z_obs is in the intervals\")\n",
    "\n",
    "    p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "    if p_value == 0:\n",
    "        print(\" WARNING: p-value is 0\")\n",
    "    if p_value is None:\n",
    "        print(\" WARNING: p-value is None\")\n",
    "\n",
    "    print(f\"Processing {step}, {p_value:.5f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.hist(p_values, density=True, bins=30, edgecolor='black')\n",
    "plt.title(\"p-value Distribution\")\n",
    "plt.xlabel(\"p-value\")\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be757a3",
   "metadata": {},
   "source": [
    "## Add paralled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa46dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 200 iterations in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 194 out of 200 | elapsed:   37.8s remaining:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Valid p-values collected: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   38.8s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed  # Import for parallelization\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import copy\n",
    "\n",
    "# Your modules\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "\n",
    "def run_single_trial(seed, n_target, n_source, p, K, Ka, h, lamda, s_vector, T):\n",
    "    \"\"\"\n",
    "    Runs a single simulation iteration.\n",
    "    \"\"\"\n",
    "    # Set unique seed for this parallel worker\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    s = len(s_vector)\n",
    "    CoRT_model = CoRT(alpha=lamda)\n",
    "    \n",
    "    # 1. Generate Data\n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    \n",
    "    # 2. Initial Model Selection (Standard Lasso on CoRT matrix)\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    # [FIX] Sort indices to ensure consistent comparison later\n",
    "    active_indices = np.sort(np.array([i for i, b in enumerate(beta_hat_target) if b != 0]))\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        return None # Skip empty selection\n",
    "\n",
    "    # 3. Construct Test Statistic\n",
    "    j = np.random.choice(len(active_indices))\n",
    "    \n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "    # 4. Path Following Initialization\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "    \n",
    "    # [OPTIMIZATION] Search window restricted to relevant probability mass\n",
    "    # Instead of [-20, 20], we look around z_obs. \n",
    "    # Standard Normal has 99.9999% mass in +/- 5.\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    \n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "\n",
    "    # 5. Path Following Loop\n",
    "    step_count = 0\n",
    "    \n",
    "    while z_k < z_max:\n",
    "        step_count += 1\n",
    "        \n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "        \n",
    "        # [FIX] Sort the active set found along the path\n",
    "        Az_target_current = np.sort(np.array([idx - offset for idx in Az if idx >= offset]))\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        mn = z_max\n",
    "        stopper = None\n",
    "\n",
    "        # Check Train Boundaries\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        # Check Val Boundaries\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        # Check CoRT Boundaries\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            z_k += 0.001\n",
    "        \n",
    "        z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        # Logic for lazy updates could go here, but kept simple for safety\n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    # 6. Extract Intervals & Calculate P-value\n",
    "    z_interval = []\n",
    "    \n",
    "    # [FIX] Ensure active_indices is sorted (already done above)\n",
    "    for i in range(len(Az_list)):\n",
    "        # [FIX] Compare sorted arrays\n",
    "        if np.array_equal(active_indices, np.sort(Az_list[i])):\n",
    "             z_interval.append([z_list[i], z_list[i+1]]) \n",
    "\n",
    "    # Merge intervals\n",
    "    new_z_interval = []\n",
    "    for interval in z_interval:\n",
    "        if len(new_z_interval) == 0:\n",
    "            new_z_interval.append(interval)\n",
    "        else:\n",
    "            dif = abs(interval[0] - new_z_interval[-1][1])\n",
    "            if dif < 0.001:\n",
    "                new_z_interval[-1][1] = interval[1]\n",
    "            else:\n",
    "                new_z_interval.append(interval)\n",
    "    z_interval = new_z_interval\n",
    "    \n",
    "    p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution Block\n",
    "# ==========================================\n",
    "n_target = 30\n",
    "n_source = 10\n",
    "p = 10\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.05\n",
    "s_vector = [0] * 1 \n",
    "T = 3\n",
    "\n",
    "iteration = 200\n",
    "\n",
    "print(f\"Starting {iteration} iterations in parallel...\")\n",
    "\n",
    "# Run in parallel using all available cores (n_jobs=-1)\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_single_trial)(i, n_target, n_source, p, K, Ka, h, lamda, s_vector, T) \n",
    "    for i in range(iteration)\n",
    ")\n",
    "\n",
    "# Filter out None results (skipped iterations)\n",
    "p_values = [res for res in results if res is not None]\n",
    "\n",
    "print(f\"Finished. Valid p-values collected: {len(p_values)}\")\n",
    "\n",
    "# Plot results\n",
    "if len(p_values) > 0:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(p_values, density=True, bins=10, edgecolor='black')\n",
    "    plt.title(f\"p-value Distribution (N={len(p_values)})\")\n",
    "    plt.xlabel(\"p-value\")\n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid p-values generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5654632",
   "metadata": {},
   "source": [
    "## Test Parallel FPR, TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d79012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 500 iterations in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 310 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 337 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 364 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 393 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 422 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 453 tasks      | elapsed:   34.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------PARAMETRIC--------------------------------------------------\n",
      "Parametric FPR: 0.0515 (Target: 0.05)\n",
      "Parametric TPR: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   37.9s finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed \n",
    "import oc\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "\n",
    "from CoRT_builder import CoRT\n",
    "import utils\n",
    "import parametric_optim\n",
    "\n",
    "def run_single_trial(seed, n_target, n_source, p, K, Ka, h, lamda, s_vector, T):\n",
    "    \"\"\"\n",
    "    Runs a single simulation iteration.\n",
    "    \"\"\"\n",
    "    # Set unique seed for this parallel worker\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    s = len(s_vector)\n",
    "    CoRT_model = CoRT(alpha=lamda)\n",
    "    \n",
    "    target_data, source_data = CoRT_model.gen_data(n_target, n_source, p, K, Ka, h, s_vector, s, \"AR\")\n",
    "    similar_source_index = CoRT_model.find_similar_source(n_target, K, target_data, source_data, T=T, verbose=False)\n",
    "    X_combined, y_combined = CoRT_model.prepare_CoRT_data(similar_source_index, source_data, target_data)\n",
    "\n",
    "    model = Lasso(alpha=lamda, fit_intercept=False, tol=1e-10, max_iter=10000000)\n",
    "    model.fit(X_combined, y_combined.ravel())\n",
    "    beta_hat_target = model.coef_[-p:]\n",
    "\n",
    "    active_indices = np.sort(np.array([i for i, b in enumerate(beta_hat_target) if b != 0]))\n",
    "\n",
    "    if len(active_indices) == 0:\n",
    "        return None \n",
    "\n",
    "    j = np.random.choice(len(active_indices))\n",
    "    selected_feature_index = active_indices[j]\n",
    "    \n",
    "    X_target = target_data[\"X\"]\n",
    "    y_target = target_data[\"y\"]\n",
    "    X_active, X_inactive = utils.get_active_X(beta_hat_target, X_target)\n",
    "\n",
    "    etaj, etajTy = utils.construct_test_statistic(y_target, j, X_active)\n",
    "\n",
    "    Sigma = np.eye(n_target)\n",
    "    b_global = Sigma @ etaj @ np.linalg.pinv(etaj.T @ Sigma @ etaj)\n",
    "    a_global = (Sigma - b_global @ etaj.T) @ y_target\n",
    "\n",
    "\n",
    "    folds = utils.split_target(T, X_target, y_target, n_target)\n",
    "\n",
    "    # Parametric\n",
    "    z_k = -20\n",
    "    z_max = 20\n",
    "\n",
    "    Z_train_list = parametric_optim.get_Z_train(z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "    Z_val_list = parametric_optim.get_Z_val(z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "\n",
    "    target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "    similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda,  n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "    X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "    L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "\n",
    "    offset = p * len(similar_source_index)\n",
    "    \n",
    "    z_list = [z_k]\n",
    "    Az_list = []\n",
    "\n",
    "    # 5. Path Following Loop\n",
    "    step_count = 0\n",
    "    matched_active_set = None\n",
    "    \n",
    "    while z_k < z_max:\n",
    "        step_count += 1\n",
    "        \n",
    "        current_num_sources = len(similar_source_current)\n",
    "        offset = p * current_num_sources\n",
    "\n",
    "        Az_target_current = np.array([idx - offset for idx in Az if idx >= offset])\n",
    "        Az_list.append(Az_target_current)\n",
    "\n",
    "        mn = z_max\n",
    "        stopper = None\n",
    "\n",
    "        for val in Z_train_list:\n",
    "            if mn > val[4]:\n",
    "                mn = val[4]\n",
    "                stopper = \"TRAIN\"\n",
    "\n",
    "        for val in Z_val_list:\n",
    "            if mn > val[3]:\n",
    "                mn = val[3]\n",
    "                stopper = \"VAL\"\n",
    "\n",
    "        if mn > R_CoRT:\n",
    "            mn = R_CoRT\n",
    "            stopper = \"CORT\"\n",
    "\n",
    "        R_final = mn\n",
    "\n",
    "        if R_final - z_k < -1e-9:\n",
    "            z_k += 1e-5\n",
    "        else:\n",
    "            z_k = max(R_final, z_k) + 1e-5\n",
    "\n",
    "        if (z_k >= z_max):\n",
    "            z_list.append(z_max)\n",
    "        else:\n",
    "            z_list.append(z_k)\n",
    "\n",
    "        update_train_needed = False\n",
    "        update_val_needed = False\n",
    "        update_cort_needed = False\n",
    "        \n",
    "        if stopper == \"TRAIN\":\n",
    "            update_train_needed = True\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"VAL\":\n",
    "            update_val_needed = True\n",
    "            update_cort_needed = True\n",
    "\n",
    "        elif stopper == \"CORT\":\n",
    "            update_cort_needed = True\n",
    "\n",
    "        if update_train_needed:\n",
    "            for val in Z_train_list:\n",
    "                if val[4] <= z_k + 1e-9:\n",
    "                    l, r = parametric_optim.update_Z_train(val, z_k, folds, source_data, a_global, b_global, lamda, K, T)\n",
    "                    val[3] = l\n",
    "                    val[4] = r\n",
    "\n",
    "        if update_val_needed:\n",
    "            for val in Z_val_list:\n",
    "                l, r = parametric_optim.update_Z_val(val, z_k, folds, T, K, a_global, b_global, lamda, source_data)\n",
    "                val[2] = l\n",
    "                val[3] = r\n",
    "\n",
    "        if update_cort_needed:\n",
    "            target_data_current = {\"X\": X_target, \"y\": a_global + z_k * b_global}\n",
    "            similar_source_current = parametric_optim.find_similar_source(z_k, a_global, b_global, lamda, n_target, K, target_data_current, source_data, T=T, verbose=False)\n",
    "            X_combined_new, y_combined_new = CoRT_model.prepare_CoRT_data(similar_source_current, source_data, target_data_current)\n",
    "            L_CoRT, R_CoRT, Az = parametric_optim.get_Z_CoRT(X_combined_new, similar_source_current, lamda, a_global, b_global, source_data, z_k)\n",
    "    \n",
    "    para_p_value = parametric_optim.pivot(active_indices, Az_list, z_list, etaj, etajTy, 0, Sigma)\n",
    "    is_signal = (selected_feature_index < s) \n",
    "    para_result_dict = {\n",
    "        \"p_value\": para_p_value,\n",
    "        \"is_signal\": is_signal,\n",
    "        \"feature_idx\": selected_feature_index\n",
    "    }\n",
    "    \n",
    "    return para_result_dict\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution Block\n",
    "# ==========================================\n",
    "n_target = 30\n",
    "n_source = 10\n",
    "p = 5\n",
    "K = 3\n",
    "Ka = 1\n",
    "h = 30\n",
    "lamda = 0.1\n",
    "alpha = 0.05\n",
    "s_vector = [1] * 1\n",
    "T = 3\n",
    "iteration = 500\n",
    "\n",
    "print(f\"Starting {iteration} iterations in parallel...\")\n",
    "\n",
    "# Run in parallel using all available cores (n_jobs=-1)\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_single_trial)(i, n_target, n_source, p, K, Ka, h, lamda, s_vector, T) \n",
    "    for i in range(iteration)\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "para_results_storage = [res for res in results if res is not None]\n",
    "print(\"-\" * 50 + \"PARAMETRIC\" + \"-\" * 50)\n",
    "para_is_signal_cases = [r for r in para_results_storage if r['is_signal']]\n",
    "para_not_signal_cases = [r for r in para_results_storage if not r['is_signal']]\n",
    "\n",
    "para_false_positives = sum(1 for c in para_not_signal_cases if c['p_value'] <= alpha)\n",
    "para_fpr = para_false_positives / len(para_not_signal_cases)\n",
    "print(f\"Parametric FPR: {para_fpr:.4f} (Target: {alpha})\")\n",
    "\n",
    "para_true_positives = sum(1 for r in para_is_signal_cases if r['p_value'] <= alpha)\n",
    "para_tpr = para_true_positives / len(para_is_signal_cases)\n",
    "print(f\"Parametric TPR: {para_tpr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CORT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
